(ns mighty.dcoref
  (:require [clojure.string :as str :refer (join)]
            [clojure.pprint :refer (pprint)]
            [mighty.config :refer (config)]
            [incanter.core :as incanter]
            [incanter.stats :as stats]
            [incanter.distributions :as dist])
  (:import (edu.stanford.nlp.pipeline StanfordCoreNLP
                                      Annotation)
           (edu.stanford.nlp.ling CoreAnnotations$SentencesAnnotation
                                  CoreAnnotations$NamedEntityTagAnnotation
                                  CoreAnnotations$TokensAnnotation
                                  CoreAnnotations$MentionTokenAnnotation)
           (edu.stanford.nlp.dcoref CorefCoreAnnotations
                                    CorefCoreAnnotations$CorefChainAnnotation
                                    CorefCoreAnnotations$CorefGraphAnnotation)
           edu.stanford.nlp.trees.tregex.TregexPattern
           edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon
           edu.stanford.nlp.trees.TreeCoreAnnotations$TreeAnnotation
           (java.lang.reflect.Method))
  )

(def ^:private props
  ;; props are properties used by the Stanford CoreNLP system. We establish a pipeline of annotation this way.
  (doto (java.util.Properties.)
    (.put "annotators" "tokenize, ssplit, pos, lemma, ner, parse, dcoref")
    (.put "parse.maxlen" (str (-> config :nlp :max-sentence-length)))
    (.put "pos.maxlen" (str (-> config :nlp :max-sentence-length)))))

(def ^:private pipeline
  ;; pipeline is the NLP stack we use to process our text.
  (StanfordCoreNLP. props))

(defn- annotated-doc [s]
  ;; This function take our text and passes it through the NLP pipeline.
  (.process pipeline s))

;; Primary fixed definitions
(def noun-tags '("NN" "NNS" "NNP" "NNPS"))
(def good-body-tags '("DT" "IN" "RP" "TO" "JJ" "JJR" "JJS" "NN" "NNS" "NNP" "NNPS"))
(def good-first-tags '("NN" "NNS" "NNP" "NNPS"))

;; primary data sources
(def raw-document (slurp "universe.txt"))
(def annotated-document (annotated-doc raw-document))
(def dcoref-chains (.get annotated-document CorefCoreAnnotations$CorefChainAnnotation))
(def chains (map #(.getValue %) dcoref-chains))
(def annotated-sentences (.get annotated-document CoreAnnotations$SentencesAnnotation))

(defn- tokens-sentence
  ;; Takes the processed document and recovers the token annotations from it.
  [annotated-sentences sentNum]
  (.get (nth annotated-sentences sentNum) CoreAnnotations$TokensAnnotation))

(defn- sentence-2-tokens
  ;; takes a single sentence and produces the token objects.
  [sentence]
  (.get sentence CoreAnnotations$TokensAnnotation))

(defn- rep-mention-coordinates
  ;; Takes a representitive mention and pulls the coordinates for it as a vector of [sentence number, start index and end index]. These values are corrected to 0-start array coordinates.
  ;; For example the first sentence is 0 not 1.
  [mention]
  (let [sentNum    (dec (.sentNum mention))
        startIndex (dec (.startIndex mention))
        endIndex   (dec (.endIndex   mention))]
    (vector sentNum startIndex endIndex))
)

(defn- select-tokens
  ;; This takes the token list and the start and end coordinates and produces a list of the token objects.
  [tokens startIndex endIndex]
  (->> tokens
     (split-at startIndex)
     second
     (split-at (- endIndex startIndex))
     first))

(defn- coord-to-tokens
  ;; This takes annotated sentences and coordinates in a vector (as generated by rep-mention-coordinates for example) and produces token objects.
  [annotated-sentences [sentNum startIndex endIndex]]
  (let [tokens (.get (nth annotated-sentences sentNum) CoreAnnotations$TokensAnnotation)]
    (select-tokens tokens startIndex endIndex)))

(defn- hash-tokens
  ;; Takes token coordinates and produces token maps.
  ;; as annotated sentences
  ;; tc token coordinates
  [as tc]
  (map #(hash-map :word (.originalText %) :ner (.ner %) :tag (.tag %)) (coord-to-tokens as tc)))

;; Noun Phrase Handling
(defn- noun-tag? [tag]
  (some #(= tag %) noun-tags))

(defn- good-body-tags? [token]
  (some #(= (:tag token) %) good-body-tags))

(defn- good-first-tag? [token]
  (some #(= (:tag token) %) good-first-tags))

(defn- just-text
  ;; ht hash tokens
  [ht]
  (map :word ht))

(defn- text-tag
  ;; ht hash tokens
  [ht]
  (map #(str (:word %) " - " (:tag %)) ht))

(defn- get-rm-text [rm as]
  (let [ht (->> rm
       rep-mention-coordinates
       (hash-tokens as))]
    (if (good-first-tag? (first ht))
      (flatten (list (:word (first ht)) (map :word (filter good-body-tags? (rest ht)))))
      (map :word (filter good-body-tags? (rest ht)))
    )
  )
)

;; filter out the mono-mentions. The remaining chains are useful
(defn- filter-chain [chain]
  (->> chain
  .getMentionMap
  count
  (< 1)))

;;example
(map #(get-rm-text (.getRepresentativeMention %) annotated-sentences) (filter filter-chain chains))

(defn- mm-get-source [mm]
  (->> mm
       .keySet
       first
       .getSource
  )
)

(defn- mm-get-target [mm]
  (->> mm
       .keySet
       first
       .getTarget
  )
)

(defn get-rm-mm [chain annotated-sentences]
  (let [rm (.getRepresentativeMention chain)
        rm-text (get-rm-text rm)
        mm (.getMentionMap chain)]
    (list rm-text (map #(hash-map :start (mm-get-source %) :end (mm-get-target %)) mm))
  ))

(map #(get-rm-mm % annotated-sentences) (filter filter-chain chain))

;Sorting with depuplication
(def unsorted-seq (stats/sample (range 100) :size 10000))

(defn dedup-sort [coll]
  (->> coll
       sort
       distinct))
(dedup-sort unsorted-seq)

(cond 100)

